{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    tot_params = 0\n",
    "    trainable_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        tot_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params:,} || all params: {tot_params:,} || trainable: {100 * trainable_params / tot_params:.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "def show_example(idx, tokenized_dataset, id2label):\n",
    "    txt = tokenized_dataset[idx][\"text\"]\n",
    "    ids = tokenized_dataset[idx]['input_ids']\n",
    "    label = tokenized_dataset[idx]['label']\n",
    "    print(f\"Text: {txt}\")\n",
    "    print(f\"Tokenized: {ids}\")\n",
    "    print(f\"Label: {label} -> {id2label[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "id2label = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "train_ds = dataset[\"train\"]\n",
    "val_ds = dataset[\"validation\"]\n",
    "test_ds = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=6, bias=False)\n",
      ")\n",
      "trainable params: 124,444,416 || all params: 124,444,416 || trainable: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\", \n",
    "    num_labels=len(id2label),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 16000\n",
      "Validation Size: 2000\n",
      "Test Size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add pad token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "tokenized_val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "tokenized_test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "\n",
    "print(f\"Training Size: {len(tokenized_train_ds)}\")\n",
    "print(f\"Validation Size: {len(tokenized_val_ds)}\")\n",
    "print(f\"Test Size: {len(tokenized_test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: i didnt feel humiliated\n",
      "Tokenized: [72, 42547, 1254, 42659, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]\n",
      "Label: 0 -> sadness\n"
     ]
    }
   ],
   "source": [
    "show_example(0, tokenized_train_ds, id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, dataset, batch_size=8):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_pred_labels = []\n",
    "    \n",
    "    N = len(dataset)\n",
    "    pbar = tqdm(total=N//batch_size)\n",
    "\n",
    "    for batch in DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        logits_array = logits.cpu().numpy()\n",
    "        all_preds.extend(logits_array)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_pred_labels.extend(np.argmax(logits_array, axis=1))\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"batch {pbar.n}/{pbar.total}\")\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    acc = compute_metrics((np.array(all_preds), np.array(all_labels)))\n",
    "    return acc, all_pred_labels, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 250/250: 100%|██████████| 250/250 [00:05<00:00, 42.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original GPT-2 model accuracy: {'accuracy': 0.036}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(f\"device: {model.device}\")\n",
    "\n",
    "# Evaluate the original GPT-2 model\n",
    "tokenized_test_dataset = tokenized_test_ds.remove_columns([\"text\"])\n",
    "tokenized_test_dataset.set_format(type='torch', columns=['label', 'input_ids', 'attention_mask'])\n",
    "\n",
    "original_acc, _, _ = evaluate(model, tokenized_test_dataset)\n",
    "print(f\"Original GPT-2 model accuracy: {original_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import TaskType\n",
    "import time\n",
    "\n",
    "def train_peft_lora(X_train, X_val, r=1, epochs=5, batch_size=16, disable_tqdm=False, save=True):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    t_start = time.time()\n",
    "    # create a peft model\n",
    "    lora_config = LoraConfig(\n",
    "        r=r,\n",
    "        lora_alpha=0.8,\n",
    "        bias=\"none\",\n",
    "        lora_dropout=0.1,\n",
    "        fan_in_fan_out=True,\n",
    "        task_type=TaskType.SEQ_CLS\n",
    "    )\n",
    "    # create a peft model\n",
    "    lora_model = get_peft_model(\n",
    "        model=model,\n",
    "        peft_config=lora_config\n",
    "    ).to(device)\n",
    "    # extract parameters\n",
    "    tot_params = sum(p.numel() for p in lora_model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in lora_model.parameters() if p.requires_grad)\n",
    "    perc_trainable = 100 * trainable_params / tot_params\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./model_dir/lora_r{r}\",\n",
    "        logging_dir=f\"./model_dir/logs/lora_r{r}\",\n",
    "        learning_rate=5e-4,\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        logging_steps=1000,\n",
    "        use_cpu=False,\n",
    "        disable_tqdm=disable_tqdm,\n",
    "        seed=110\n",
    "    )\n",
    "    # LoRA uses \"labels\", not \"label\". We need to rename the datasets.\n",
    "    train_lora = X_train.rename_column('label', 'labels')\n",
    "    val_lora = X_val.rename_column('label', 'labels')\n",
    "    # Trainer object\n",
    "    trainer = Trainer(\n",
    "        model=lora_model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_lora,\n",
    "        eval_dataset=val_lora,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    if save:\n",
    "        trainer.save_model(f\"./model_dir/fine_tuned_model/lora_r{r}\")\n",
    "        #tokenizer.save_pretrained(f\"./model_dir/fine_tuned_model/lora_r{r}\")\n",
    "        #torch.save(training_args, f\"./model_dir/fine_tuned_model/lora_r{r}/training_args.bin\")\n",
    "        #trainer.state.save_to_json(f\"./model_dir/fine_tuned_model/lora_r{r}/trainer_state.json\")\n",
    "\n",
    "    # evaluate the model\n",
    "    acc = trainer.evaluate()['eval_accuracy']\n",
    "    t_end = time.time()\n",
    "    output = {\n",
    "        'r': r,\n",
    "        'trainable_params': trainable_params,\n",
    "        'tot_params': tot_params,\n",
    "        'perc_trainable': perc_trainable,\n",
    "        'accuracy': acc,\n",
    "        'time': t_end - t_start\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b692ebb9161d4f2b839f08e2f92ba129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bdc6ed0d41479ca9ec1b2917758525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40435791015625, 'eval_accuracy': 0.8545, 'eval_runtime': 5.7253, 'eval_samples_per_second': 349.325, 'eval_steps_per_second': 11.004, 'epoch': 1.0}\n",
      "{'loss': 0.6974, 'grad_norm': 3.1234071254730225, 'learning_rate': 0.0003, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e67909fc34c40b8b35ed57af90f5cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2844401001930237, 'eval_accuracy': 0.903, 'eval_runtime': 5.7064, 'eval_samples_per_second': 350.483, 'eval_steps_per_second': 11.04, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4127efa57b462ca53dd9f702836063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2444622963666916, 'eval_accuracy': 0.9115, 'eval_runtime': 5.6232, 'eval_samples_per_second': 355.668, 'eval_steps_per_second': 11.204, 'epoch': 3.0}\n",
      "{'loss': 0.3141, 'grad_norm': 5.904489517211914, 'learning_rate': 0.0001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3217233c104d8bb0bb8ef51e4c2d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2283259630203247, 'eval_accuracy': 0.9175, 'eval_runtime': 5.5026, 'eval_samples_per_second': 363.463, 'eval_steps_per_second': 11.449, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667e04ef634743c7896d49780b5f2292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22251750528812408, 'eval_accuracy': 0.9145, 'eval_runtime': 5.5374, 'eval_samples_per_second': 361.181, 'eval_steps_per_second': 11.377, 'epoch': 5.0}\n",
      "{'train_runtime': 532.9199, 'train_samples_per_second': 150.116, 'train_steps_per_second': 4.691, 'train_loss': 0.4592796630859375, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7719d6c03f194c438e277e2e94ecae16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6a804be1e04a1c955dd5fffdec63cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e404a973d0433e966efb80e7d13290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4057578146457672, 'eval_accuracy': 0.8575, 'eval_runtime': 4.875, 'eval_samples_per_second': 410.259, 'eval_steps_per_second': 12.923, 'epoch': 1.0}\n",
      "{'loss': 0.6975, 'grad_norm': 3.5390725135803223, 'learning_rate': 0.0003, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d6c8bf8cf145059cc212d8d7326d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2919744849205017, 'eval_accuracy': 0.8945, 'eval_runtime': 4.8351, 'eval_samples_per_second': 413.638, 'eval_steps_per_second': 13.03, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b231875ad404bf88726f5ed82e02027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2502692937850952, 'eval_accuracy': 0.9125, 'eval_runtime': 5.2325, 'eval_samples_per_second': 382.228, 'eval_steps_per_second': 12.04, 'epoch': 3.0}\n",
      "{'loss': 0.3138, 'grad_norm': 5.42918062210083, 'learning_rate': 0.0001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f48ff7666f426d9401f94d85d8881e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23090820014476776, 'eval_accuracy': 0.918, 'eval_runtime': 5.2519, 'eval_samples_per_second': 380.812, 'eval_steps_per_second': 11.996, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965eed2d201649b9bb8ea81a04b7ea5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2259306013584137, 'eval_accuracy': 0.913, 'eval_runtime': 5.2261, 'eval_samples_per_second': 382.694, 'eval_steps_per_second': 12.055, 'epoch': 5.0}\n",
      "{'train_runtime': 488.0849, 'train_samples_per_second': 163.906, 'train_steps_per_second': 5.122, 'train_loss': 0.4590067687988281, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf8051c1184495d901e193f9ae58e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5707f07663342f69c9f5d7fde98fa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d0d89182d74efeb745ef606cad3316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40412425994873047, 'eval_accuracy': 0.857, 'eval_runtime': 5.9157, 'eval_samples_per_second': 338.084, 'eval_steps_per_second': 10.65, 'epoch': 1.0}\n",
      "{'loss': 0.697, 'grad_norm': 3.0872411727905273, 'learning_rate': 0.0003, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82e79247e74432a99422e26abd88a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2885330021381378, 'eval_accuracy': 0.8995, 'eval_runtime': 5.2045, 'eval_samples_per_second': 384.286, 'eval_steps_per_second': 12.105, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e05969a2d1402390519decf99bbe7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24612893164157867, 'eval_accuracy': 0.914, 'eval_runtime': 5.2258, 'eval_samples_per_second': 382.717, 'eval_steps_per_second': 12.056, 'epoch': 3.0}\n",
      "{'loss': 0.3124, 'grad_norm': 5.261791706085205, 'learning_rate': 0.0001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909816cf0a394ce4abb3f016025a30a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22674840688705444, 'eval_accuracy': 0.9145, 'eval_runtime': 5.2303, 'eval_samples_per_second': 382.386, 'eval_steps_per_second': 12.045, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54c9b0f5d8047e2ae4d34fd27eff7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22137726843357086, 'eval_accuracy': 0.917, 'eval_runtime': 5.256, 'eval_samples_per_second': 380.519, 'eval_steps_per_second': 11.986, 'epoch': 5.0}\n",
      "{'train_runtime': 620.7953, 'train_samples_per_second': 128.867, 'train_steps_per_second': 4.027, 'train_loss': 0.45804074096679687, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b8d652c8094bd29a9c4494399d2fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b0d4af2d5a461296bc744fc6e7a925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6974fde90214420c8e4cfee5f42ddfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40465080738067627, 'eval_accuracy': 0.8585, 'eval_runtime': 5.3282, 'eval_samples_per_second': 375.361, 'eval_steps_per_second': 11.824, 'epoch': 1.0}\n",
      "{'loss': 0.698, 'grad_norm': 3.1393556594848633, 'learning_rate': 0.0003, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04bc418d2b7440d96a31c91480e609e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29046598076820374, 'eval_accuracy': 0.8975, 'eval_runtime': 5.5423, 'eval_samples_per_second': 360.863, 'eval_steps_per_second': 11.367, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4fad3b7968434487bdd4f93e97a00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24734307825565338, 'eval_accuracy': 0.915, 'eval_runtime': 5.6054, 'eval_samples_per_second': 356.802, 'eval_steps_per_second': 11.239, 'epoch': 3.0}\n",
      "{'loss': 0.3123, 'grad_norm': 5.491448402404785, 'learning_rate': 0.0001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2758fe563b544613a202f83bb0484291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22780083119869232, 'eval_accuracy': 0.916, 'eval_runtime': 4.9664, 'eval_samples_per_second': 402.709, 'eval_steps_per_second': 12.685, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a6d2ed719c48c2b0b9e17cbb938a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2222987413406372, 'eval_accuracy': 0.915, 'eval_runtime': 4.8112, 'eval_samples_per_second': 415.7, 'eval_steps_per_second': 13.095, 'epoch': 5.0}\n",
      "{'train_runtime': 530.6766, 'train_samples_per_second': 150.751, 'train_steps_per_second': 4.711, 'train_loss': 0.45867125854492186, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5355ddef6164711a46690d864ed183b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba4a34d4c234a9b8331e18cc9baaa1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58175a4957154172b53f1d7411a06f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40234193205833435, 'eval_accuracy': 0.8585, 'eval_runtime': 29.8094, 'eval_samples_per_second': 67.093, 'eval_steps_per_second': 2.113, 'epoch': 1.0}\n",
      "{'loss': 0.697, 'grad_norm': 3.0910911560058594, 'learning_rate': 0.0003, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806c882bbd48451b9edd003f0a8860f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28797420859336853, 'eval_accuracy': 0.8995, 'eval_runtime': 35.8236, 'eval_samples_per_second': 55.829, 'eval_steps_per_second': 1.759, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da205b343b404d2b9394a66aaf034084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2446276992559433, 'eval_accuracy': 0.915, 'eval_runtime': 34.0598, 'eval_samples_per_second': 58.72, 'eval_steps_per_second': 1.85, 'epoch': 3.0}\n",
      "{'loss': 0.3101, 'grad_norm': 5.37736701965332, 'learning_rate': 0.0001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0147b0ffa1d473b8ef50e1f3fd21ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2251196801662445, 'eval_accuracy': 0.9155, 'eval_runtime': 35.8127, 'eval_samples_per_second': 55.846, 'eval_steps_per_second': 1.759, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d29c61debd49bbb4851cfe4022e355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2196282297372818, 'eval_accuracy': 0.914, 'eval_runtime': 36.0373, 'eval_samples_per_second': 55.498, 'eval_steps_per_second': 1.748, 'epoch': 5.0}\n",
      "{'train_runtime': 1591.5876, 'train_samples_per_second': 50.264, 'train_steps_per_second': 1.571, 'train_loss': 0.4568334655761719, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b138383d1148f39efa48bf708983fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_lora_perfs = {}\n",
    "\n",
    "# Train the model with LoRA\n",
    "r_vals = [1, 2, 4, 8, 16]\n",
    "\n",
    "for r in r_vals:\n",
    "    output_lora_perfs[r] = train_peft_lora(\n",
    "    X_train=tokenized_train_ds, \n",
    "    X_val=tokenized_val_ds, \n",
    "    r=r, \n",
    "    epochs=5, \n",
    "    batch_size=32,\n",
    "    save=True,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "    \n",
    "output_lora_perfs = pd.DataFrame(output_lora_perfs).T\n",
    "output_lora_perfs.to_csv(\"lora_perfs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ae441d841849469041ef4118b62cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b79266d3ef4e5caa0a1a85aaed6a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.404478520154953, 'eval_accuracy': 0.8565, 'eval_runtime': 4.9422, 'eval_samples_per_second': 404.679, 'eval_steps_per_second': 12.747, 'epoch': 1.0}\n",
      "{'loss': 0.6972, 'grad_norm': 3.652996778488159, 'learning_rate': 0.0003, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f479c4512d84b2d994ad45ba71000c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2811495363712311, 'eval_accuracy': 0.9045, 'eval_runtime': 4.9428, 'eval_samples_per_second': 404.631, 'eval_steps_per_second': 12.746, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa36ddf43844c25a410005a61980cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24415400624275208, 'eval_accuracy': 0.915, 'eval_runtime': 4.9629, 'eval_samples_per_second': 402.994, 'eval_steps_per_second': 12.694, 'epoch': 3.0}\n",
      "{'loss': 0.3137, 'grad_norm': 4.638004779815674, 'learning_rate': 0.0001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060ad9d82e8a471eb7afce1c7575b992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2269621193408966, 'eval_accuracy': 0.9175, 'eval_runtime': 4.84, 'eval_samples_per_second': 413.224, 'eval_steps_per_second': 13.017, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9333af63333f4332b013f02349e19e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22183148562908173, 'eval_accuracy': 0.919, 'eval_runtime': 4.8239, 'eval_samples_per_second': 414.605, 'eval_steps_per_second': 13.06, 'epoch': 5.0}\n",
      "{'train_runtime': 471.0543, 'train_samples_per_second': 169.832, 'train_steps_per_second': 5.307, 'train_loss': 0.458707666015625, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bb95cab86e45ebbef2a00b6ad2645a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf = train_peft_lora(\n",
    "    X_train=tokenized_train_ds, \n",
    "    X_val=tokenized_val_ds, \n",
    "    r=1, \n",
    "    epochs=5, \n",
    "    batch_size=32,\n",
    "    disable_tqdm=False,\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "batch 63/62: : 63it [00:04, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA model accuracy: {'accuracy': 0.904}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "config = PeftConfig.from_pretrained(\"./model_dir/fine_tuned_model/lora_r1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path, num_labels=len(id2label))\n",
    "# resize the token embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# set the pad token\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "# load the peft model\n",
    "lora_model = PeftModel.from_pretrained(model, \"./model_dir/fine_tuned_model/lora_r1\").to(device)\n",
    "# Inference using the trained model\n",
    "acc, all_pred_labels, all_labels = evaluate(lora_model, tokenized_test_dataset, batch_size=32)\n",
    "\n",
    "print(f\"LoRA model accuracy: {acc}\")\n",
    "\n",
    "# Prepare the prediction table\n",
    "examples_df = pd.DataFrame(tokenized_test_ds.select_columns([\"text\", \"label\"]))\n",
    "examples_df['emotion'] = examples_df['label'].map(id2label)\n",
    "examples_df['predicted_label'] = all_pred_labels\n",
    "examples_df['predicted_emotion'] = examples_df['predicted_label'].map(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel irritable about the number of people that came into our office whining about their own circumstances i realize im not practicing thinking about the good things and i find it a better way to pull yourself into the present</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel appalled right now</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel that i am afraid of whatever ad anything that will happen and idc is it good or bad i am just afraid and i hope god you will help me in whatever i do</td>\n",
       "      <td>4</td>\n",
       "      <td>fear</td>\n",
       "      <td>4</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i guess feelings aren t meant to be inhibited or prohibited</td>\n",
       "      <td>4</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i bought this doraemon backpack from a charity store i had every intention of putting it in my etsy store but i feel like its too cute to sell</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i feel for this divine landmass and all the respect i bear in my heart for the greatness residing on it</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i feel that i am supporting the troops by demanding that we not send our young men and women into harm s way to bear arms against a country that has done nothing to threaten us at any point</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i feel very tender for anyone who is upset by the bee movie sort of like how you feel about old aunts who dont realize how prickly their whiskers are getting slightly repulsed but very sad for their decline</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i came home waiting for the shower read something which made me upset thats why i feel discontent haha</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im starting to feel really pathetic giving the bulk of my enthusiasm these days to the kardashians us weekly and roseanne marathons and completely ignoring this blog</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i wonder if the homeowners would feel weird if i parked to gape at their landscaping</td>\n",
       "      <td>5</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i feel thats just strange on wotcs behalf</td>\n",
       "      <td>5</td>\n",
       "      <td>surprise</td>\n",
       "      <td>5</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                   text  \\\n",
       "0   i feel irritable about the number of people that came into our office whining about their own circumstances i realize im not practicing thinking about the good things and i find it a better way to pull yourself into the present   \n",
       "1                                                                                                                                                                                                             i feel appalled right now   \n",
       "2                                                                          i feel that i am afraid of whatever ad anything that will happen and idc is it good or bad i am just afraid and i hope god you will help me in whatever i do   \n",
       "3                                                                                                                                                                           i guess feelings aren t meant to be inhibited or prohibited   \n",
       "4                                                                                        i bought this doraemon backpack from a charity store i had every intention of putting it in my etsy store but i feel like its too cute to sell   \n",
       "5                                                                                                                               i feel for this divine landmass and all the respect i bear in my heart for the greatness residing on it   \n",
       "6                                         i feel that i am supporting the troops by demanding that we not send our young men and women into harm s way to bear arms against a country that has done nothing to threaten us at any point   \n",
       "7                        i feel very tender for anyone who is upset by the bee movie sort of like how you feel about old aunts who dont realize how prickly their whiskers are getting slightly repulsed but very sad for their decline   \n",
       "8                                                                                                                                i came home waiting for the shower read something which made me upset thats why i feel discontent haha   \n",
       "9                                                                 im starting to feel really pathetic giving the bulk of my enthusiasm these days to the kardashians us weekly and roseanne marathons and completely ignoring this blog   \n",
       "10                                                                                                                                                 i wonder if the homeowners would feel weird if i parked to gape at their landscaping   \n",
       "11                                                                                                                                                                                            i feel thats just strange on wotcs behalf   \n",
       "\n",
       "    label   emotion  predicted_label predicted_emotion  \n",
       "0       3     anger                3             anger  \n",
       "1       3     anger                3             anger  \n",
       "2       4      fear                4              fear  \n",
       "3       4      fear                0           sadness  \n",
       "4       1       joy                1               joy  \n",
       "5       1       joy                1               joy  \n",
       "6       2      love                2              love  \n",
       "7       2      love                2              love  \n",
       "8       0   sadness                3             anger  \n",
       "9       0   sadness                0           sadness  \n",
       "10      5  surprise                5          surprise  \n",
       "11      5  surprise                5          surprise  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified sampling\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "examples_df.groupby('emotion').apply(lambda x: x.sample(2, random_state=110)).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
